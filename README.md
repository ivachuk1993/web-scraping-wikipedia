# ğŸ“Š Web Scraping da Wikipedia

## ğŸ‡§ğŸ‡· PortuguÃªs

Projeto de web scraping em Python que coleta dados da Wikipedia e salva em arquivos CSV.

### ğŸ”§ Funcionalidades
- Realiza scraping de dados da Wikipedia usando `pandas` e `lxml`.
- Salva os dados coletados em arquivos `.csv`.

### ğŸš€ Como usar
1. Clone este repositÃ³rio:  
   `git clone https://github.com/ivachuk1993/web-scraping-wikipedia.git`

2. Entre na pasta do projeto:  
   `cd web-scraping-wikipedia`

3. Crie e ative um ambiente virtual:

   **Windows:**  
   `python -m venv venv`  
   `venv\Scripts\activate`

   **Linux/macOS:**  
   `python3 -m venv venv`  
   `source venv/bin/activate`

4. Instale as dependÃªncias:  
   `pip install pandas lxml`

5. Execute o script principal:  
   `python webscraping_wiki.py`

---

## ğŸ‡ºğŸ‡¸ English

Python web scraping project that collects data from Wikipedia and saves it as CSV files.

### ğŸ”§ Features
- Scrapes data from Wikipedia using `pandas` and `lxml`.
- Saves the scraped data into `.csv` files.

### ğŸš€ How to Use
1. Clone this repository:  
   `git clone https://github.com/ivachuk1993/web-scraping-wikipedia.git`

2. Navigate to the project folder:  
   `cd web-scraping-wikipedia`

3. Create and activate a virtual environment:

   **Windows:**  
   `python -m venv venv`  
   `venv\Scripts\activate`

   **Linux/macOS:**  
   `python3 -m venv venv`  
   `source venv/bin/activate`

4. Install dependencies:  
   `pip install pandas lxml`

5. Run the main script:  
   `python webscraping_wiki.py`

---

## ğŸ‘¤ Autora / Author

**VerÃ´nica Ivachuk**  
ğŸ“§ veronicasivachuk@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/veronica-ivachuk/)
